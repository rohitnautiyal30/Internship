{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b23000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2355f9",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "### Q) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Main_Page'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ed7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_tag = soup.find_all([\"h1\", \"h2\"])\n",
    "\n",
    "header_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making list of header tags\n",
    "\n",
    "header_texts = []\n",
    "\n",
    "for tag in header_tag:\n",
    "    header_texts.append(tag.get_text())\n",
    "    \n",
    "header_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe of header tags\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Headers\": header_texts})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aba282",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Q) Write a python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2 = \"https://presidentofindia.nic.in/former-presidents\"\n",
    "\n",
    "page_2 = requests.get(url_2)\n",
    "\n",
    "page_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af412db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_2.content)\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting names of former presidents\n",
    "\n",
    "name = soup.find_all('h3')\n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b860705",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e58fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list of names\n",
    "\n",
    "names = []\n",
    "\n",
    "for i in name:\n",
    "    names.append(i.get_text())\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1777c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484232ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the term of office of former presidents\n",
    "\n",
    "# Since the data of term of office is not given, thus I am extracting data of their precidency order.\n",
    "\n",
    "order = soup.find_all('h5')\n",
    "\n",
    "order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5033df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list of names\n",
    "\n",
    "order_of_presidents = []\n",
    "\n",
    "for i in order :\n",
    "    order_of_presidents.append(i.get_text())\n",
    "    \n",
    "order_of_presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(order), '\\n',len(order_of_presidents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05998ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe\n",
    "\n",
    "df_2 = pd.DataFrame({'Name': names,'Order': order_of_presidents})\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c93bd",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "#\n",
    "\n",
    "### Q) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame-\n",
    "### i) Paper Title\n",
    "### ii) Authors\n",
    "### iii) Published Date\n",
    "### iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "\n",
    "page= requests.get(url)\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find_all('h2', class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\")\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9da647",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for i in title:\n",
    "    titles.append(i.text)\n",
    "    \n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb755c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = soup.find_all('span', class_='sc-1w3fpd7-0 dnCnAO')\n",
    "\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa344efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "\n",
    "for i in author:\n",
    "    authors.append(i.text)\n",
    "    \n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65734083",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = soup.find_all('span', class_=\"sc-1thf9ly-2 dvggWt\")\n",
    "\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cf4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "\n",
    "for i in date:\n",
    "    dates.append(i.text)\n",
    "    \n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb0d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\")\n",
    "\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f30e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for i in link:\n",
    "    links.append(i.get(\"href\"))\n",
    "    \n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7774618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Paper Title\" : titles, \"Authors\" : authors, \"Published Date\" : dates, \"Paper URL\": links})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4555d",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "### Q) Write a python program to scrape mentioned details from dineout.co.in and make data frame-\n",
    "### i) Restaurant name\n",
    "### ii) Cuisine\n",
    "### iii) Location\n",
    "### iv) Ratings\n",
    "### v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find_all('div', class_=\"restnt-info cursor\")\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for i in title:\n",
    "    titles.append(i.text)\n",
    "    \n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = soup.find_all('div', class_=\"restnt-loc ellipsis\")\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6917213",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = []\n",
    "\n",
    "for i in location :\n",
    "    \n",
    "    locations.append(i.text)\n",
    "    \n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = soup.find_all('span', class_=\"double-line-ellipsis\")\n",
    "\n",
    "cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89832999",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = []\n",
    "\n",
    "for i in cuisine:\n",
    "    cuisines.append(i.text)\n",
    "    \n",
    "cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0714258",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = soup.find_all('div', class_=\"restnt-rating rating-4\")\n",
    "\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e27b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "\n",
    "for i in rating:\n",
    "    ratings.append(i.text)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27513b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = soup.find_all('img', class_=\"no-img\")\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec19527",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in image:\n",
    "    images.append(i.get(\"data-src\"))\n",
    "    \n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc930b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating database\n",
    "\n",
    "df = pd.DataFrame({\"Restaurant Name\": titles, \"Cuisine\": cuisines, \"Location\": locations, \"Ratings\": ratings, \"Image URL\": images})\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
